import threading
import sys
import subprocess
import shlex
import argparse
import re
from pathlib import Path
import os
import pandas as pd
import shutil
import math
from Bio import SeqIO
import csv

# å¯¼å…¥whether_passåˆ—æ·»åŠ åŠŸèƒ½
try:
    from modify_mpnn_report import add_whether_pass_column
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥modify_mpnn_reportæ¨¡å—ï¼Œwhether_passåˆ—åŠŸèƒ½å°†ä¸å¯ç”¨")
    add_whether_pass_column = None


def parse_args():
    parser = argparse.ArgumentParser(description='Protein sequence prediction and report generation', 
                                   formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument("--seq_folder", type=str,
                        help="Folder containing MPNN generated fasta files")
    parser.add_argument("--output_folder", type=str,
                        help="Folder for storing output files")
    parser.add_argument("--final_report_folder", type=str, default=None,
                        help="Folder for storing final mpnn_report.csv (default: same as output_folder)")
    parser.add_argument('--top_percent', type=float, default=0.2,
                        help='Filter sequences with the lowest global_score by percentage (default: 0.2 for 20%)')
    parser.add_argument('--position_list', type=str, default=None, 
                        help='Redesigned sequence region for cluster analysis')
    parser.add_argument("-t", "--threads", type=int, default=8,
                        help="MMseqs2 number of threads (default: 8)")
    parser.add_argument("--min_seq_id", type=float, default=None,
                        help="Minimum sequence similarity (default: 0.8)")
    parser.add_argument("--cov_mode", type=int, default=0,
                        help="Coverage mode (0 = bidirectional, 1 = query, default: 0)")
    parser.add_argument("-c", "--coverage", type=float, default=0.8,
                        help="Coverage threshold (default: 0.8)")
    parser.add_argument("--mmseqs_path", type=str, default="mmseqs",
                        help="mmseqs command path (default: mmseqs)")
    parser.add_argument("-s", "--sensitivity",type=float, default=4.0,
                        help="Sensitivity: 1.0 faster; 4.0 fast; 7.5 sensitive [4.000]")
    parser.add_argument("--generate_report", type=bool, default=True,
                        help="Generate comprehensive MPNN report")
    parser.add_argument("--rfdiffusion_report_path", type=str, default=None,
                        help="The path to rfdiffusion_report.csv. If not entered, the default path will be used: {work_dir}/rfdiffusion_report.csv")
    
    return parser.parse_args()


def extract_sequences_from_fasta(file_path):
    """
    ä»FASTAæ–‡ä»¶ä¸­æå–åºåˆ—æ•°æ®ï¼ŒåŒºåˆ†åˆå§‹åºåˆ—å’Œç”Ÿæˆåºåˆ—
    """
    sequences = []
    try:
        with open(file_path, 'r') as f:
            for record in SeqIO.parse(f, "fasta"):
                # è§£æå¤´éƒ¨ä¿¡æ¯
                header = record.description
                
                # æå–å±æ€§
                attributes = {}
                header_parts = header.split(', ')
                for part in header_parts:
                    if '=' in part:
                        key, value = part.split('=', 1)
                        attributes[key.strip()] = value.strip()
                
                sequence_data = {
                    'header': header,
                    'attributes': attributes,
                    'sequence': str(record.seq),
                    'id': record.id
                }
                sequences.append(sequence_data)
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™ï¼š{e}")
        return []
    
    return sequences


def natural_sort_key(filename):
    """ç”Ÿæˆè‡ªç„¶æ’åºçš„keyï¼šå°†æ–‡ä»¶åæ‹†åˆ†ä¸ºå­—ç¬¦ä¸²å’Œæ•°å­—éƒ¨åˆ†ï¼Œæ•°å­—è½¬æ•´æ•°"""
    parts = re.split(r'(\d+)', os.path.splitext(filename)[0])
    key = []
    for part in parts:
        if part.isdigit():
            key.append(int(part))
        else:
            key.append(part)
    return key


def load_backbone_data_from_rfdiffusion(working_dir, rfdiffusion_report_path = None):
    """
    ä»rfdiffusion_report.csvä¸­åŠ è½½éª¨æ¶æ•°æ®
    """
    backbone_data = {}
    try:
        # æ„å»ºrfdiffusion_report.csvçš„å®Œæ•´è·¯å¾„
        if rfdiffusion_report_path == 'None' or rfdiffusion_report_path is None:
            rf_report_path = os.path.join(working_dir, 'rfdiffusion_report.csv')
        else:
            rf_report_path = rfdiffusion_report_path
        #if not os.path.exists(rf_report_path):
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
           # rf_report_path = os.path.join(working_dir, 'rfdiffusion_out', 'rfdiffusion_report.csv')
        
        if os.path.exists(rf_report_path):
            df_rf = pd.read_csv(rf_report_path)
            for _, row in df_rf.iterrows():
                backbone_index = row['index']
                backbone_data[backbone_index] = {
                    'ss8': row.get('design_ss8', ''),
                    'ss3': row.get('design_ss3', ''),
                    'H_prop': row.get('H_prop', 0.0),
                    'E_prop': row.get('E_prop', 0.0),
                    'C_prop': row.get('C_prop', 0.0),
                    'backbone': row.get('backbone', ''),
                    'success_backbone': row.get('success_backbone', ''),
                    'Success': row.get('Success', '')
                }
            print(f"å·²åŠ è½½ {len(backbone_data)} ä¸ªéª¨æ¶çš„æ•°æ®")
        else:
            print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°rfdiffusion_report.csvæ–‡ä»¶: {rf_report_path}")
            
    except Exception as e:
        print(f"è¯»å–rfdiffusion_report.csvæ—¶å‡ºé”™ï¼š{e}")
    
    return backbone_data


def get_design_region_positions():
    """
    è·å–è®¾è®¡åŒºåŸŸçš„ä½ç½®ä¿¡æ¯ï¼ˆ346-394ï¼‰
    """
    # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…é…ç½®æ–‡ä»¶è¯»å–ï¼Œæš‚æ—¶ç¡¬ç¼–ç 
    return 346, 394


def generate_csv_for_fasta(seq_file_path, output_folder, fa_filename, working_dir, rfdiffusion_report_path = None):
    """
    ä¸ºå•ä¸ªFASTAæ–‡ä»¶ç”ŸæˆCSVæ–‡ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„éª¨æ¶ä¿¡æ¯å’ŒMPNNæ•°æ®
    """
    print(f"å¤„ç†æ–‡ä»¶ï¼š{fa_filename}")
    
    # æå–æ‰€æœ‰åºåˆ—
    sequences = extract_sequences_from_fasta(seq_file_path)
    
    if not sequences:
        print(f"æ–‡ä»¶ {fa_filename} ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆåºåˆ—")
        return None
    
    # ç¬¬ä¸€ä¸ªåºåˆ—æ˜¯åˆå§‹åºåˆ—ï¼Œåç»­æ˜¯ç”Ÿæˆåºåˆ—
    generated_sequences = sequences[1:] if len(sequences) > 1 else []
    
    if not generated_sequences:
        print(f"æ–‡ä»¶ {fa_filename} ä¸­æ²¡æœ‰æ‰¾åˆ°ç”Ÿæˆåºåˆ—")
        return None
    
    # ä»rfdiffusion_report.csvåŠ è½½éª¨æ¶æ•°æ®
    backbone_data = load_backbone_data_from_rfdiffusion(working_dir, rfdiffusion_report_path)
    #print(f"backbone data: {backbone_data}")
    
    # æå–éª¨æ¶IDï¼ˆä»æ–‡ä»¶åå¦‚"Dusp4_A_2"ï¼‰
    backbone_id = fa_filename.replace('.fa', '')
    
    # è·å–è®¾è®¡åŒºåŸŸä½ç½®
    design_start, design_end = get_design_region_positions()
    
    # è·å–å¯¹åº”çš„éª¨æ¶æ•°æ®
    backbone_info = backbone_data.get(backbone_id, {
        'ss8': '',
        'ss3': '',
        'H_prop': 0.0,
        'E_prop': 0.0,
        'C_prop': 0.0,
        'backbone': '',
        'success_backbone': '',
        'Success': ''
    })
    #print(f"backbone info: {backbone_info}")
    
    # å‡†å¤‡CSVæ•°æ®
    csv_data = []
    
    for idx, seq_data in enumerate(generated_sequences):
        # æå–MPNNå±æ€§
        score = float(seq_data['attributes'].get('score', '0.0'))
        global_score = float(seq_data['attributes'].get('global_score', '0.0'))
        
        # è®¡ç®—è®¾è®¡åŒºåŸŸåºåˆ—ï¼ˆä»è®¾è®¡åŒºåŸŸä½ç½®æå–ï¼‰
        full_sequence = seq_data['sequence']
        if len(full_sequence) >= design_end:
            design_region = full_sequence[design_start-1:design_end]  # Pythonç´¢å¼•ä»0å¼€å§‹
        else:
            design_region = full_sequence
        
        csv_row = {
            'index': f"{backbone_id}_mpnn_{idx}",
            'backbone': backbone_id,
            'ss8': backbone_info['ss8'],
            'ss3': backbone_info['ss3'],
            'H_prop': backbone_info['H_prop'],
            'E_prop': backbone_info['E_prop'],
            'C_prop': backbone_info['C_prop'],
            'backbone_pdb': backbone_info['success_backbone'] if backbone_info['success_backbone'] != '-' else backbone_info['backbone'],
            'score': score,
            'global_score': global_score,
            'region': design_region,
            'sequence': full_sequence
        }
        csv_data.append(csv_row)
    
    # ç”ŸæˆCSVæ–‡ä»¶å
    csv_filename = f"mpnn_{backbone_id}.csv"
    csv_path = os.path.join(output_folder, csv_filename)
    
    # ä¿å­˜CSVæ–‡ä»¶
    df = pd.DataFrame(csv_data)
    df.to_csv(csv_path, index=False)
    
    print(f"å·²ç”ŸæˆCSVæ–‡ä»¶ï¼š{csv_filename}ï¼ŒåŒ…å« {len(csv_data)} ä¸ªåºåˆ—")
    return csv_path, csv_data


def filter_top_sequences(csv_data, top_percent):
    """
    æ ¹æ®global_scoreç­›é€‰æœ€ä½çš„top_percentç™¾åˆ†æ¯”åºåˆ—ï¼ˆä¿æŒåŸå§‹indexé¡ºåºï¼‰
    """
    if not csv_data:
        return []
    
    # æŒ‰global_scoreæ’åºï¼ˆå‡åºï¼Œæ•°å€¼è¶Šä½è¶Šå¥½ï¼‰ä»¥æ‰¾å‡ºéœ€è¦ä¿ç•™çš„åºåˆ—
    sorted_data = sorted(csv_data, key=lambda x: x['global_score'])
    
    # è®¡ç®—éœ€è¦ä¿ç•™çš„åºåˆ—æ•°é‡
    total_sequences = len(sorted_data)
    n = max(1, math.ceil(total_sequences * top_percent))
    
    # è·å–éœ€è¦ä¿ç•™çš„åºåˆ—çš„indexï¼ˆæŒ‰åŸå§‹é¡ºåºï¼‰
    top_indices = {seq['index'] for seq in sorted_data[:n]}
    
    # æŒ‰åŸå§‹é¡ºåºè¿”å›ç­›é€‰åçš„åºåˆ—
    filtered_sequences = [seq for seq in csv_data if seq['index'] in top_indices]
    
    return filtered_sequences


def process_all_fasta_files(seq_folder, output_folder, top_percent, rfdiffusion_report_path = None):
    """
    å¤„ç†æ‰€æœ‰FASTAæ–‡ä»¶å¹¶ç”Ÿæˆç›¸åº”çš„CSVæ–‡ä»¶
    """
    print(f"å¼€å§‹å¤„ç†FASTAæ–‡ä»¶...")
    print(f"è¾“å…¥æ–‡ä»¶å¤¹ï¼š{seq_folder}")
    print(f"è¾“å‡ºæ–‡ä»¶å¤¹ï¼š{output_folder}")
    
    # è·å–å·¥ä½œç›®å½•ï¼ˆå‡è®¾seq_folderåœ¨å·¥ä½œç›®å½•ä¸‹çš„mpnn_out/seqsï¼‰
    working_dir = output_folder.rsplit('/', 1)[0]
    print(f"å·¥ä½œç›®å½•ï¼š{working_dir}")
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(output_folder, exist_ok=True)
    
    # è·å–æ‰€æœ‰FASTAæ–‡ä»¶
    fa_files = sorted([f for f in os.listdir(seq_folder) if f.endswith('.fa')], 
                     key=natural_sort_key)
    
    if not fa_files:
        print(f"åœ¨æ–‡ä»¶å¤¹ {seq_folder} ä¸­æ²¡æœ‰æ‰¾åˆ°FASTAæ–‡ä»¶")
        return [], []
    
    print(f"æ‰¾åˆ° {len(fa_files)} ä¸ªFASTAæ–‡ä»¶")
    
    # åˆ›å»ºseqs_csvæ–‡ä»¶å¤¹
    seqs_csv_folder = os.path.join(output_folder, 'seqs_csv')
    os.makedirs(seqs_csv_folder, exist_ok=True)
    
    # å¤„ç†æ¯ä¸ªFASTAæ–‡ä»¶
    all_csv_data = []
    generated_files = []
    
    # åˆ›å»ºtop_percentæ–‡ä»¶å¤¹
    top_percent_str = f"{top_percent*100:.1f}%"
    top_folder = os.path.join(output_folder, f'top_{top_percent_str}')
    os.makedirs(top_folder, exist_ok=True)
    
    # å¯¹æ¯ä¸ªFASTAæ–‡ä»¶ç‹¬ç«‹è¿›è¡Œç­›é€‰
    top_generated_files = []
    
    for fa_file in fa_files:
        fa_file_path = os.path.join(seq_folder, fa_file)
        
        result = generate_csv_for_fasta(fa_file_path, seqs_csv_folder, fa_file, working_dir, rfdiffusion_report_path)
        if result:
            csv_path, csv_data = result
            generated_files.append(csv_path)
            all_csv_data.extend(csv_data)
            
            # å¯¹å½“å‰æ–‡ä»¶çš„åºåˆ—è¿›è¡Œç‹¬ç«‹ç­›é€‰
            top_sequences_current = filter_top_sequences(csv_data, top_percent)
            
            if top_sequences_current:
                base_name = os.path.splitext(fa_file)[0]
                top_csv_filename = f"top_mpnn_{base_name}.csv"
                top_csv_path = os.path.join(top_folder, top_csv_filename)
                
                df = pd.DataFrame(top_sequences_current)
                df.to_csv(top_csv_path, index=False)
                top_generated_files.append(top_csv_path)
                
                print(f"å·²ç”ŸæˆTopåºåˆ—CSVæ–‡ä»¶ï¼š{top_csv_filename}ï¼ŒåŒ…å« {len(top_sequences_current)} ä¸ªåºåˆ—")
            else:
                print(f"æ–‡ä»¶ {fa_file} ä¸­æ²¡æœ‰ç¬¦åˆç­›é€‰æ¡ä»¶çš„åºåˆ—")
    
    print(f"Topåºåˆ—å·²ä¿å­˜åˆ°æ–‡ä»¶å¤¹ï¼š{top_folder}")
    
    return generated_files, top_generated_files


def get_start_end(input_str):
    """
    æå–è¾“å…¥ä¸­çš„å¼€å§‹æ•°å­—å’Œç»“æŸæ•°å­—
    """
    if " " in input_str:
        num_list = [int(num) for num in input_str.split()]
        return num_list[0], num_list[-1]
    elif "-" in input_str:
        match = re.match(r"^[A-Za-z]*(\d+)-(\d+)$", input_str)
        if match:
            start = int(match.group(1))
            end = int(match.group(2))
            return start, end
    else:
        match = re.match(r"^[A-Za-z]*(\d+)$", input_str)
        if match:
            num = int(match.group(1))
            return num, num
    return None, None


def generate_final_mpnn_report(output_folder, top_percent, position_list, final_report_folder=None):
    """
    ç”Ÿæˆæœ€ç»ˆçš„mpnn_report.csvæ–‡ä»¶ï¼ŒåŒ…å«æ‰€æœ‰åºåˆ—
    
    å‚æ•°:
        output_folder: è¾“å‡ºæ–‡ä»¶å¤¹
        top_percent: topç­›é€‰ç™¾åˆ†æ¯”
        final_report_folder: æœ€ç»ˆæŠ¥å‘Šè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆé»˜è®¤ä¸ºoutput_folderï¼‰
    """
    print("ç”Ÿæˆæœ€ç»ˆçš„MPNNæŠ¥å‘Šï¼ˆåŒ…å«æ‰€æœ‰åºåˆ—ï¼‰...")
    segment = position_list
    if position_list and position_list[0].isalpha():  # æ£€æŸ¥å­—ç¬¦ä¸²éç©ºä¸”é¦–å­—ç¬¦æ˜¯å­—æ¯
        segment = position_list[1:]  # åˆ é™¤é¦–å­—ç¬¦

    # ç¡®å®šæœ€ç»ˆæŠ¥å‘Šè¾“å‡ºè·¯å¾„
    if final_report_folder is None:
        final_report_folder = output_folder.rsplit('/', 1)[0]
    
    # åªè¯»å–æ‰€æœ‰åŸå§‹åºåˆ—CSVæ–‡ä»¶
    seqs_csv_folder = os.path.join(output_folder, 'seqs_csv')
    top_percent_str = f"{top_percent*100:.1f}%"
    top_folder = os.path.join(output_folder, f'top_{top_percent_str}')
    
    # è·å–æ‰€æœ‰åºåˆ—çš„indexé›†åˆï¼ˆç”¨äºæ ‡è®°æ˜¯å¦ä¸ºTopåºåˆ—ï¼‰
    top_sequence_indices = set()
    if os.path.exists(top_folder):
        top_csv_files = [f for f in os.listdir(top_folder) if f.endswith('.csv')]
        for csv_file in top_csv_files:
            csv_path = os.path.join(top_folder, csv_file)
            df_top = pd.read_csv(csv_path)
            top_sequence_indices.update(df_top['index'].tolist())
    
    report_data = []
    
    # å¤„ç†æ‰€æœ‰åŸå§‹åºåˆ—CSVæ–‡ä»¶
    if os.path.exists(seqs_csv_folder):
        csv_files = [f for f in os.listdir(seqs_csv_folder) if f.endswith('.csv')]
        
        for csv_file in csv_files:
            csv_path = os.path.join(seqs_csv_folder, csv_file)
            df = pd.read_csv(csv_path)
            
            for _, row in df.iterrows():
                # æ£€æŸ¥è¯¥åºåˆ—æ˜¯å¦åœ¨Topç­›é€‰ä¸­
                is_top_sequence = row['index'] in top_sequence_indices
                
                report_entry = {
                    'index': row['index'],
                    'backbone': row.get('backbone', ''),
                    'segment': segment,
                    'ss8': row.get('ss8', ''),
                    'ss3': row.get('ss3', ''),
                    'H_prop': row.get('H_prop', ''),
                    'E_prop': row.get('E_prop', ''),
                    'C_prop': row.get('C_prop', ''),
                    'backbone_pdb': row.get('backbone_pdb', ''),
                    'score': row['score'],
                    'global_core': row['global_score'],
                    'region': row.get('region', ''),
                    'sequence': row['sequence']
                }
                report_data.append(report_entry)
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    if report_data:
        final_report_path = os.path.join(final_report_folder, 'mpnn_report.csv')
        df_final = pd.DataFrame(report_data)
        df_final.to_csv(final_report_path, index=False)
        
        print(f"æœ€ç»ˆMPNNæŠ¥å‘Šå·²ç”Ÿæˆï¼š{final_report_path}")
        print(f"åŒ…å« {len(report_data)} æ¡è®°å½•")
        
        # æ·»åŠ whether_passåˆ—ï¼ˆå¦‚æœèšç±»åˆ†æå·²å®Œæˆï¼‰
        if add_whether_pass_column is not None:
            try:
                result_folder = os.path.join(output_folder, 'results')
                if os.path.exists(result_folder):
                    print("ğŸ”„ å¼€å§‹æ·»åŠ whether_passåˆ—...")
                    add_whether_pass_column(final_report_path, result_folder)
                    print("âœ… whether_passåˆ—æ·»åŠ æˆåŠŸ")
                else:
                    print("â„¹ï¸  æœªæ‰¾åˆ°èšç±»ç»“æœæ–‡ä»¶å¤¹ï¼Œè·³è¿‡whether_passåˆ—æ·»åŠ ")
            except Exception as e:
                print(f"âš ï¸  æ·»åŠ whether_passåˆ—æ—¶å‡ºé”™: {e}")
        
        return final_report_path
    else:
        print("æ²¡æœ‰æ•°æ®ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        return None


if __name__ == "__main__":
    args = parse_args()
    seq_folder = os.path.expanduser(args.seq_folder)
    output_folder = os.path.expanduser(args.output_folder)
    top_percent = args.top_percent
    rfdiffusion_report_path = args.rfdiffusion_report_path
    position_list = args.position_list
    
    print("=== MPNNåºåˆ—å¤„ç†å’ŒæŠ¥å‘Šç”Ÿæˆ ===")
    print(f"è¾“å…¥åºåˆ—æ–‡ä»¶å¤¹: {seq_folder}")
    print(f"è¾“å‡ºæ–‡ä»¶å¤¹: {output_folder}")
    print(f"Topç­›é€‰ç™¾åˆ†æ¯”: {top_percent*100:.1f}%")
    
    # å¤„ç†æ‰€æœ‰FASTAæ–‡ä»¶å¹¶ç”ŸæˆCSV
    all_csv_files, top_csv_files = process_all_fasta_files(seq_folder, output_folder, top_percent, rfdiffusion_report_path)
    
    if all_csv_files:
        print(f"\næˆåŠŸå¤„ç† {len(all_csv_files)} ä¸ªCSVæ–‡ä»¶")
        if top_csv_files:
            print(f"æˆåŠŸç”Ÿæˆ {len(top_csv_files)} ä¸ªTopåºåˆ—CSVæ–‡ä»¶")


        
        # å¦‚æœæä¾›äº†args.min_seq_idï¼Œè¿›è¡Œèšç±»åˆ†æ
        if args.min_seq_id and top_csv_files:
            print(f"\nå¼€å§‹èšç±»åˆ†æ...")
            threads = args.threads
            min_seq_id = args.min_seq_id
            cov_mode = args.cov_mode
            coverage = args.coverage
            mmseqs_path = args.mmseqs_path
            sensitivity = args.sensitivity
            
            start, end = get_start_end(position_list)
            if start is not None and end is not None:
                # åˆ›å»ºresultæ–‡ä»¶å¤¹åœ¨mpnn_outç›®å½•ä¸‹
                results_folder = os.path.join(output_folder, 'results')
                if not os.path.exists(results_folder):
                    os.makedirs(results_folder, exist_ok=True)

                # å¯¹æ¯ä¸ªtop CSVæ–‡ä»¶è¿›è¡Œèšç±»åˆ†æ
                for top_csv_file in top_csv_files:
                    print(f"å¯¹æ–‡ä»¶ {os.path.basename(top_csv_file)} è¿›è¡Œèšç±»åˆ†æ...")

                    # ä»æ–‡ä»¶åæå–éª¨æ¶åç§°ï¼Œç”¨äºåŒ¹é…cluster_analysis.pyä¸­çš„é€»è¾‘
                    base_name = os.path.splitext(os.path.basename(top_csv_file))[0]
                    if base_name.startswith('top_mpnn_'):
                        skeleton_name = base_name.split('_',2)[-1]
                    else:
                        skeleton_name = base_name

                    # åˆ›å»ºéª¨æ¶ç‰¹å®šçš„è¾“å‡ºæ–‡ä»¶å¤¹
                    skeleton_folder = os.path.join(output_folder, 'cluster_data', skeleton_name)
                    os.makedirs(skeleton_folder, exist_ok=True)

                    # ç›´æ¥è°ƒç”¨cluster_analysis.pyä¸­çš„comprehensiveå‡½æ•°
                    try:
                        from cluster_analysis import comprehensive
                        
                        # è°ƒç”¨comprehensiveå‡½æ•°
                        comprehensive(
                            input_file=top_csv_file,
                            output_folder=Path(skeleton_folder),
                            filename=f"{skeleton_name}.fa",  # ä½¿ç”¨éª¨æ¶åç§°
                            work_directory=results_folder,
                            start=start,
                            end=end,
                            threads=threads,
                            min_seq_id=min_seq_id,
                            cov_mode=cov_mode,
                            coverage=coverage,
                            mmseqs_path=mmseqs_path
                        )
                        
                        print(f"èšç±»åˆ†ææˆåŠŸå®Œæˆ")
                        print(f"è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: {results_folder}")
                        
                    except Exception as e:
                        print(f"èšç±»åˆ†æå¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()

                    print(f"èšç±»åˆ†æå®Œæˆ")

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        if args.generate_report:
            final_report_path = generate_final_mpnn_report(output_folder, top_percent, position_list, args.final_report_folder)
            if final_report_path:
                print(f"\n[SUCCESS] å®Œæ•´MPNNæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                print(f"[OUTPUT] ä¸»è¦è¾“å‡ºæ–‡ä»¶:")
                print(f"   - åŸå§‹åºåˆ—CSV: {output_folder}/seqs_csv/")
                print(f"   - Topåºåˆ—CSV: {output_folder}/top_{top_percent * 100:.1f}%/")
                print(f"   - æœ€ç»ˆæŠ¥å‘Š: {final_report_path}")
    else:
        print("[ERROR] æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")
        sys.exit(1)